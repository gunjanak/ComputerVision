{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e352e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import joblib\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48975bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, output_video_path=\"Output/output.mp4\", log_path=\"recognition_log.txt\",MODEL_PATH=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    mtcnn = MTCNN(image_size=160, margin=20, device=device)\n",
    "    resnet = InceptionResnetV1(pretrained=\"vggface2\").eval().to(device)\n",
    "\n",
    "    data = joblib.load(MODEL_PATH)\n",
    "    clf = data[\"classifier\"]\n",
    "    encoder = data[\"encoder\"]\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Read and verify FPS\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps == 0 or np.isnan(fps):\n",
    "        fps = 25.0  # Safe default\n",
    "        print(\"‚ö†Ô∏è FPS was 0 or invalid. Defaulting to 25 FPS.\")\n",
    "    else:\n",
    "        print(f\"üéûÔ∏è Detected FPS: {fps}\")\n",
    "\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration_sec = total_frames / fps\n",
    "    print(f\"üé• Input video has {total_frames} frames, duration ~ {duration_sec:.2f} seconds.\")\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    log = open(log_path, \"w\")\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        boxes, _ = mtcnn.detect(img_rgb)\n",
    "\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                x1, y1 = max(x1, 0), max(y1, 0)\n",
    "                x2, y2 = min(x2, frame.shape[1]), min(y2, frame.shape[0])\n",
    "\n",
    "                face = img_rgb[y1:y2, x1:x2]\n",
    "                if face.size == 0:\n",
    "                    continue\n",
    "                face_resized = cv2.resize(face, (160, 160))\n",
    "                face_tensor = torch.tensor(face_resized).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "                face_tensor = face_tensor.to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    embedding = resnet(face_tensor).cpu().numpy().flatten()\n",
    "\n",
    "                probs = clf.predict_proba([embedding])[0]\n",
    "                max_prob = max(probs)\n",
    "                label = encoder.inverse_transform([np.argmax(probs)])[0] if max_prob > 0.6 else \"Unknown\"\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{label} ({max_prob:.2f})\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                timestamp = str(timedelta(seconds=frame_idx / fps))\n",
    "                log.write(f\"[{timestamp}] {label} ({max_prob:.2f})\\n\")\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    log.close()\n",
    "\n",
    "    output_duration = frame_idx / fps\n",
    "    print(f\"Finished. Total frames written: {frame_idx} (~{output_duration:.2f} seconds at {fps} FPS).\")\n",
    "    print(f\"Output video saved to: {output_video_path}\")\n",
    "    print(f\"Log saved to: {log_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f4e1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"Models/face_recognition2.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1407127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéûÔ∏è Detected FPS: 29.97002997002997\n",
      "üé• Input video has 215 frames, duration ~ 7.17 seconds.\n",
      "Finished. Total frames written: 215 (~7.17 seconds at 29.97002997002997 FPS).\n",
      "Output video saved to: Output/output.mp4\n",
      "Log saved to: recognition_log.txt\n"
     ]
    }
   ],
   "source": [
    "input_video = \"test_files/aa.webm\"\n",
    "process_video(input_video,MODEL_PATH=MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
