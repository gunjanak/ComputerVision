{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b018dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723ef615",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"Models/face_recognition2.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0c3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load face detection and embedding models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mtcnn = MTCNN(image_size=160, margin=20, device=device)\n",
    "resnet = InceptionResnetV1(pretrained=\"vggface2\").eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6b740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained classifier\n",
    "data = joblib.load(MODEL_PATH)\n",
    "clf = data[\"classifier\"]\n",
    "encoder = data[\"encoder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aafe13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_face():\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)  # Open webcam\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return None\n",
    "\n",
    "    start_time = time.time()\n",
    "    captured_face = None\n",
    "\n",
    "    while time.time() - start_time < 10:  # Run for 10 seconds\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        # Convert to RGB format for MTCNN\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img_pil = Image.fromarray(img_rgb)\n",
    "\n",
    "        # Detect faces\n",
    "        boxes, _ = mtcnn.detect(img_pil)\n",
    "\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "                # Crop the first detected face\n",
    "                captured_face = img_rgb[y1:y2, x1:x2]\n",
    "\n",
    "                # Show the detected face\n",
    "                display(Image.fromarray(captured_face))\n",
    "\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                return captured_face  # Return the cropped face\n",
    "\n",
    "        cv2.imshow(\"Webcam - Detecting Face\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Press ESC to exit\n",
    "            break\n",
    "\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"No face detected within 10 seconds.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89f8fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(face_image):\n",
    "    print(\"Hello\")\n",
    "    if face_image is None:\n",
    "        print(\"No face to recognize!\")\n",
    "        return\n",
    "    \n",
    "    # Resize face for FaceNet\n",
    "    face = cv2.resize(face_image, (160, 160))\n",
    "    print(\"Face resized\")\n",
    "    \n",
    "    # Convert to tensor\n",
    "    face = torch.tensor(face).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "    face = face.to(device)\n",
    "\n",
    "    # Extract embedding\n",
    "    embedding = resnet(face).detach().cpu().numpy().flatten()\n",
    "\n",
    "    # Predict identity\n",
    "    probs = clf.predict_proba([embedding])[0]\n",
    "    max_prob = max(probs)\n",
    "    predicted_label = encoder.inverse_transform([np.argmax(probs)])[0]\n",
    "\n",
    "    # Display result\n",
    "    person_name = predicted_label if max_prob > 0.6 else \"Unknown\"\n",
    "    print(f\"Recognized Person: {person_name} ({max_prob:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "764df631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAyACQDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDqdItUisoUUD5QK6K1jUYyK5/R2IsoyWXGBzurYN5HawtLIcKo5xXyTb5tT6rEJydkaF1lowAK5XXNL/tS1eDISQD5W9DViTxePN8qRVtoj0dvmY/hipIbqG+Tz4JjLHnBLLtOaJuSfMiaNOdP4keYDS5VG2ZNsikhgfaitXVr4R6xeDa2PNOBiiuhYidjp+rQZXs4JrtlFtC4IIBZpME8V32gLcTW00F4AZYQMHg7gelYfh0qumxLNFGZFyCdoPeul0aUS3k5UrsZQAR3xWVWfvWsKtGUab8iM6DH57MY45A7BvnGcYramsRFYAKqjPYDGKgn89j/AKM4LjqpHFVDrLktazBkmXqrenqKzcmo6nI/a1bNPY8+8RaXdDWpniDFZMNwM+3r7UV2cgR23Mu4nvRUqsenGorK6ON0G+keSWzVlR3JK7x0PNW7CbWI9VNpaxeXKwG5HkAXjuDWPrcyQ6olzZYBJY7lPXmtm2uh4geGaFlivEXbLG3f3rqlH7Vi41U26b/E7iKG6tLXEtzHGSM7IxubP1NV5bDaizyM0kp+8z8n6e1N0fSJIpFkubjzCOgHT/69W9YvFjCwow3t0rKolynm3aq8kHfu7WMWSR95CYwOKKfFDtQAUVw8vmdnMloea3P+vA9qs6S7R6/ZFGKkvg7TjIoor2l/DOeX8U9ayQpwcVzEzM2uzBmJAAxk9KKK4JdSsH8cvQ1I/uUUUVylPc//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=36x50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "face = capture_face()  # Step 1: Capture face\n",
    "#    # Step 2: Recognize face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "152753b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Face resized\n",
      "Recognized Person: Aisha (0.77)\n"
     ]
    }
   ],
   "source": [
    "recognize_face(face)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
